{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 数据准备\n",
    "导入包以及数据"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# --- Explore HMM POS Taggers using Brown corpus ---\n",
    "\n",
    "# In this assignment, you will explore two taggers for a Brown corpus.\n",
    "\n",
    "# import your packages here\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import string\n",
    "import nltk"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据加载及探索\n",
    "加载训练和测试语料库，分别用一个列表表示，列表中的每个元素都是一个句子，这个句子是一个元组列表，其中每一个元组第一个元素是单词，第二个元素是POS标记。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bb55db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load all tags and print it out\n",
    "\"\"\"\n",
    "file_tag = open('NLP_PJ3/brown-tag.txt', mode='r')\n",
    "tags = [x.strip() for x in file_tag.readlines()]\n",
    "file_tag.close()\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load corpus files and count sentences and words in datasets\n",
    "\"\"\"\n",
    "def open_and_count(root):\n",
    "    f = open(root, mode='r')\n",
    "    corpus = []\n",
    "    sent = []\n",
    "    count_sent = 0\n",
    "    count_word = 0\n",
    "    tag_word_dict = defaultdict(int)\n",
    "    for line in f:\n",
    "        if re.match('b\\d+-\\d+', line):\n",
    "            if sent:\n",
    "                corpus.append(sent)\n",
    "                count_sent += 1\n",
    "            sent = []\n",
    "        elif line != '\\n':\n",
    "            sent.append(tuple(line.split()))\n",
    "            count_word += 1\n",
    "            tag_word_dict[sent[-1][1]] += 1\n",
    "    corpus.append(sent)\n",
    "    count_sent += 1\n",
    "    f.close()\n",
    "    return corpus, count_sent, count_word, tag_word_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_corpus, train_sent, train_word, train_tag_word = open_and_count('NLP_PJ3/brown-train.txt')\n",
    "test_corpus, test_sent, test_word, test_tag_word = open_and_count('NLP_PJ3/brown-test.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 45800 sentences and 928327 words in train corpus.\n",
      "There are 11540 sentences and 232865 words in test corpus.\n",
      "For each tag, the number of words in train and test corpus are as follow:\n",
      ".: [117723, 29842]\n",
      "ADJ: [66985, 16736]\n",
      "ADP: [115752, 29014]\n",
      "ADV: [44765, 11474]\n",
      "CONJ: [30455, 7696]\n",
      "DET: [109418, 27601]\n",
      "NOUN: [220451, 55107]\n",
      "NUM: [11921, 2953]\n",
      "PRON: [39657, 9677]\n",
      "PRT: [23889, 5940]\n",
      "VERB: [146199, 36551]\n",
      "X: [1112, 274]\n"
     ]
    }
   ],
   "source": [
    "print('There are {} sentences and {} words in train corpus.'.format(train_sent, train_word))\n",
    "print('There are {} sentences and {} words in test corpus.'.format(test_sent, test_word))\n",
    "print('For each tag, the number of words in train and test corpus are as follow:')\n",
    "for tag in tags:\n",
    "    print(\"{}: [{}, {}]\".format(tag, train_tag_word[tag], test_tag_word[tag]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Baseline Method\n",
    "使用最大频率标注器进行词性标注，并探索不同的unknown words处理方法对模型效果的影响。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d633df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Find the frequency of label for each word in the training data\n",
    "\"\"\"\n",
    "train_vocab = defaultdict(lambda :defaultdict(int))\n",
    "for sent in train_corpus:\n",
    "    for word, tag in sent:\n",
    "        train_vocab[word][tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of train sample using baseline method is 95.71961173164198\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Predict tag for train datasets. In train corpus there will not be unknown words.\n",
    "\"\"\"\n",
    "correct = 0\n",
    "for sent in train_corpus:\n",
    "    for word, tag in sent:\n",
    "        pred_tag = max(train_vocab[word], key=lambda x: train_vocab[word][x])\n",
    "        if pred_tag == tag:\n",
    "            correct += 1\n",
    "print('The accuracy of train sample using baseline method is', correct/train_word*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of test sample using baseline method is 93.03802632426513\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Predict tag for test datasets. And try different method to process unknown words.\n",
    "\"\"\"\n",
    "# Method 1: Simply mark the unknown word with tag \"UNK\"\n",
    "correct = 0\n",
    "for sent in test_corpus:\n",
    "    for word, tag in sent:\n",
    "        if word in train_vocab:\n",
    "            pred_tag = max(train_vocab[word], key=lambda x: train_vocab[word][x])\n",
    "            if pred_tag == tag:\n",
    "                correct += 1\n",
    "        else:\n",
    "            continue\n",
    "print('The accuracy of test sample using baseline method is', correct/test_word*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "在训练集上的准确率超过了90%，也确实高于在测试集上的预测结果。\n",
    "以上结果是不对unknown words做任何处理的结果，因此之后任何处理unknown words的方法准确率都不应低于该值。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of test sample using baseline method is 94.51871255877869\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Tag the unknown words with the majority tag among all training samples.\n",
    "most_freq_tag = max(train_tag_word, key=lambda x:train_tag_word[x])\n",
    "correct = 0\n",
    "for sent in test_corpus:\n",
    "    for word, tag in sent:\n",
    "        if word in train_vocab:\n",
    "            pred_tag = max(train_vocab[word], key=lambda x: train_vocab[word][x])\n",
    "            if pred_tag == tag:\n",
    "                correct += 1\n",
    "        else:\n",
    "            pred_tag = most_freq_tag\n",
    "            if pred_tag == tag:\n",
    "                correct += 1\n",
    "print('The accuracy of test sample using baseline method is', correct/test_word*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到测试集上的准确率确实上升了一些，但是无论给这些unknown words标注什么tag，准确率都会有不同幅度的上升。希望找到更加细致的标注划分方式。\n",
    "下面参考了Adamouization的unknown words标注方法，对unknown words进行进一步的细粒度划分。我将划分之后依旧没有对应tag的words称为real unknown words，请和unknown words区分。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Method 3: Use word spelling rules tag unknown words\n",
    "# SUBMETHOD 1: Use 'UNK' tag the real unknown words\n",
    "NOUN_SUFFIX = [\"action\", \"age\", \"ance\", \"cy\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"ism\", \"ist\", \"ity\", \" ling\", \"ment\", \"ness\", \"or\", \"ry\", \"scape\", \"ship\", \"dom\", \"ty\"]\n",
    "VERB_SUFFIX = [\"ate\", \"ify\", \"ise\", \"ize\", \"ed\", \"ing\"]\n",
    "ADJ_SUFFIX = [\"able\", \"ese\", \"ful\", \"i\", \"ian\", \"ible\", \"ic\", \"ish\", \"ive\", \"less\", \"ly\", \"ous\"]\n",
    "ADV_SUFFIX = [\"ward\", \"wards\", \"wise\"]\n",
    "UNK_TAG = 'UNK'  # real unknown words tag\n",
    "PUNC_TAG = '.'\n",
    "def unknown_words_rules(word):\n",
    "    if any(char.isdigit() for char in word):\n",
    "        return 'NUM'\n",
    "    elif any(char in set(string.punctuation) for char in word):\n",
    "        return PUNC_TAG\n",
    "    elif any(word.endswith(suffix) for suffix in NOUN_SUFFIX):\n",
    "        return 'NOUN'\n",
    "    elif any(word.endswith(suffix) for suffix in VERB_SUFFIX):\n",
    "        return 'VERB'\n",
    "    elif any(word.endswith(suffix) for suffix in ADJ_SUFFIX):\n",
    "        return 'ADJ'\n",
    "    elif any(word.endswith(suffix) for suffix in ADV_SUFFIX):\n",
    "        return 'ADV'\n",
    "    else:\n",
    "        return UNK_TAG"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of test sample using baseline method is 93.6907650355356\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for sent in test_corpus:\n",
    "    for word, tag in sent:\n",
    "        if word in train_vocab:\n",
    "            pred_tag = max(train_vocab[word], key=lambda x: train_vocab[word][x])\n",
    "            if pred_tag == tag:\n",
    "                correct += 1\n",
    "        else:\n",
    "            pred_tag = unknown_words_rules(word)\n",
    "            if pred_tag == tag:\n",
    "                correct += 1\n",
    "print('The accuracy of test sample using baseline method is', correct/test_word*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到准确率比最初全部预测为'UNK'要高一些，说明这种划分方法是有效的。接下来，考虑到前面将unknown words预测为tag库中已有的tag可以提高准确率，在这里也将real unknown words标注一个tag。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of test sample using baseline method is 94.55822042814506\n"
     ]
    }
   ],
   "source": [
    "# SUBMETHOD 2: Tag the real unknown words with the majority tag among all training samples.\n",
    "UNK_TAG = most_freq_tag\n",
    "correct = 0\n",
    "for sent in test_corpus:\n",
    "    for word, tag in sent:\n",
    "        if word in train_vocab:\n",
    "            pred_tag = max(train_vocab[word], key=lambda x: train_vocab[word][x])\n",
    "            if pred_tag == tag:\n",
    "                correct += 1\n",
    "        else:\n",
    "            pred_tag = unknown_words_rules(word)\n",
    "            if pred_tag == tag:\n",
    "                correct += 1\n",
    "print('The accuracy of test sample using baseline method is', correct/test_word*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "模型的准确率有稍微的上升。\n",
    "考虑到也许real unknown words都是比较特别的单词才不在语料库中，试试改变real unknown words的tag为'X'。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of test sample using baseline method is 93.73628497197947\n"
     ]
    }
   ],
   "source": [
    "# SUBMETHOD3: Tag the real unknown words with 'X'.\n",
    "UNK_TAG = 'X'\n",
    "correct = 0\n",
    "for sent in test_corpus:\n",
    "    for word, tag in sent:\n",
    "        if word in train_vocab:\n",
    "            pred_tag = max(train_vocab[word], key=lambda x: train_vocab[word][x])\n",
    "            if pred_tag == tag:\n",
    "                correct += 1\n",
    "        else:\n",
    "            pred_tag = unknown_words_rules(word)\n",
    "            if pred_tag == tag:\n",
    "                correct += 1\n",
    "print('The accuracy of test sample using baseline method is', correct/test_word*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "模型准确率反而有所下降，至少说明real unknown words大部分为'X'这种猜测是有问题的。但是前面的想法有一定道理，使用更加有依据的方法去修正unknown words的tag。\n",
    "总结一下前面的想法：上面的算法默认将识别不出来的单词标记为所有训练数据集中出现频率最高的那个标签，但这其中可能有一个问题是：**所有训练语料库**中出现最频繁的标签有可能并不等价于**unknown words语料库**真实标签出现最频繁的标签（比如可能就是因为某个tag出现的频率太低才会导致unknown words的出现）。\n",
    "尝试用训练集中只出现了一次的单词模拟测试集中的unknown words语料库。我在这里将训练集中只出现一次的单词构成的语料库成为稀疏语料库，代码中使用unique words来表示对应单词。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent tag between unique words in train datasets is NOUN\n"
     ]
    }
   ],
   "source": [
    "# Count the most frequent tag between the words that only appear once in train datasets\n",
    "word_freq_dist = Counter([word[0] for sent in train_corpus for word in sent])\n",
    "unique_word_tag_dist = defaultdict(int)\n",
    "for word in word_freq_dist.keys():\n",
    "    if word_freq_dist[word] != 1:\n",
    "        continue\n",
    "    unique_word_tag_dist[list(train_vocab[word].keys())[0]] += 1\n",
    "print('The most frequent tag between unique words in train datasets is', max(unique_word_tag_dist, key=lambda x:unique_word_tag_dist[x]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "确实证实了NOUN是出现频率最高的tag，无论是在完整数据集还是稀疏数据集中。\n",
    "同样的idea，第二个可能存在的问题是：上面使用的unknown_word_rules在完整数据集中看很合理，但在稀疏数据集中是否也保持一致呢？进一步地，在稀疏数据集中的most frequent tag又是否会和real unknown word中的most frequent tag一致呢？\n",
    "和上面类似，采用在稀疏数据集上模拟的方法来验证。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "tag2tag = defaultdict(lambda :defaultdict(int))\n",
    "for word in word_freq_dist.keys():\n",
    "    if word_freq_dist[word] != 1:\n",
    "        continue\n",
    "    if any(char.isdigit() for char in word):\n",
    "        tag2tag['NUM'][list(train_vocab[word].keys())[0]] += 1\n",
    "    elif any(char in set(string.punctuation) for char in word):\n",
    "        tag2tag['.'][list(train_vocab[word].keys())[0]] += 1\n",
    "    elif any(word.endswith(suffix) for suffix in NOUN_SUFFIX):\n",
    "        for suffix in NOUN_SUFFIX:\n",
    "            if word.endswith(suffix):\n",
    "                tag2tag[suffix][list(train_vocab[word].keys())[0]] += 1\n",
    "                break\n",
    "    elif any(word.endswith(suffix) for suffix in VERB_SUFFIX):\n",
    "        for suffix in VERB_SUFFIX:\n",
    "            if word.endswith(suffix):\n",
    "                tag2tag[suffix][list(train_vocab[word].keys())[0]] += 1\n",
    "                break\n",
    "    elif any(word.endswith(suffix) for suffix in ADJ_SUFFIX):\n",
    "        for suffix in ADJ_SUFFIX:\n",
    "            if word.endswith(suffix):\n",
    "                tag2tag[suffix][list(train_vocab[word].keys())[0]] += 1\n",
    "                break\n",
    "    elif any(word.endswith(suffix) for suffix in ADV_SUFFIX):\n",
    "        for suffix in ADV_SUFFIX:\n",
    "            if word.endswith(suffix):\n",
    "                tag2tag[suffix][list(train_vocab[word].keys())[0]] += 1\n",
    "                break\n",
    "    else:\n",
    "        tag2tag['UNK'][list(train_vocab[word].keys())[0]] += 1   # 对real unknown word进一步调整"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "来检查是否有区别："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM\n",
      "NOUN\n",
      "NOUN\n"
     ]
    }
   ],
   "source": [
    "print(max(tag2tag['NUM'], key=lambda x:tag2tag['NUM'][x]))\n",
    "print(max(tag2tag['.'], key=lambda x:tag2tag['.'][x]))\n",
    "print(max(tag2tag['UNK'], key=lambda x:tag2tag['UNK'][x]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到'NUM'的tag没有变化，real unknown word的most frequent tag也确实是'NOUN'没有变。但是原本被判定为'.'的tag变成了'NOUN'！\n",
    "更进一步，看看suffix的原定tag是否有出现变化的："
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tag change in NOUN_SUFFIX:\n",
      "************************************************\n",
      "The tag change in VERB_SUFFIX:\n",
      "The tag of suffix ise change from VERB to NOUN.\n",
      "************************************************\n",
      "The tag change in ADJ_SUFFIX:\n",
      "The tag of suffix ese change from ADJ to NOUN.\n",
      "The tag of suffix i change from ADJ to NOUN.\n",
      "The tag of suffix ly change from ADJ to ADV.\n",
      "************************************************\n",
      "The tag change in NOUN_SUFFIX:\n",
      "************************************************\n"
     ]
    }
   ],
   "source": [
    "print('The tag change in NOUN_SUFFIX:')\n",
    "for suffix in NOUN_SUFFIX:\n",
    "    if tag2tag[suffix] and max(tag2tag[suffix], key=lambda x:tag2tag[suffix][x]) != 'NOUN':\n",
    "        print('The tag of suffix {} change from NOUN to {}.'.format(suffix, max(tag2tag[suffix], key=lambda x:tag2tag[suffix][x])))\n",
    "print('************************************************')\n",
    "print('The tag change in VERB_SUFFIX:')\n",
    "for suffix in VERB_SUFFIX:\n",
    "    if tag2tag[suffix] and max(tag2tag[suffix], key=lambda x:tag2tag[suffix][x]) != 'VERB':\n",
    "        print('The tag of suffix {} change from VERB to {}.'.format(suffix, max(tag2tag[suffix], key=lambda x:tag2tag[suffix][x])))\n",
    "print('************************************************')\n",
    "print('The tag change in ADJ_SUFFIX:')\n",
    "for suffix in ADJ_SUFFIX:\n",
    "    if tag2tag[suffix] and max(tag2tag[suffix], key=lambda x:tag2tag[suffix][x]) != 'ADJ':\n",
    "        print('The tag of suffix {} change from ADJ to {}.'.format(suffix, max(tag2tag[suffix], key=lambda x:tag2tag[suffix][x])))\n",
    "print('************************************************')\n",
    "print('The tag change in NOUN_SUFFIX:')\n",
    "for suffix in ADV_SUFFIX:\n",
    "    if tag2tag[suffix] and max(tag2tag[suffix], key=lambda x:tag2tag[suffix][x]) != 'ADV':\n",
    "        print('The tag of suffix {} change from ADV to {}.'.format(suffix, max(tag2tag[suffix], key=lambda x:tag2tag[suffix][x])))\n",
    "print('************************************************')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到有四种suffix的tag都发生了变化！在对应的suffix tag列表进行修改，同时也修改前面探索过的UNK-TAG、PUNC-TAG。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "VERB_SUFFIX.remove('ise')\n",
    "ADJ_SUFFIX.remove('ese')\n",
    "ADJ_SUFFIX.remove('i')\n",
    "ADJ_SUFFIX.remove('ly')\n",
    "NOUN_SUFFIX.append('ise')\n",
    "NOUN_SUFFIX.append('ese')\n",
    "NOUN_SUFFIX.append('i')\n",
    "ADV_SUFFIX.append('ly')\n",
    "UNK_TAG = 'NOUN'\n",
    "PUNC_TAG = 'NOUN'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of test sample using baseline method is 94.92667425332274\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for sent in test_corpus:\n",
    "    for word, tag in sent:\n",
    "        if word in train_vocab:\n",
    "            pred_tag = max(train_vocab[word], key=lambda x: train_vocab[word][x])\n",
    "            if pred_tag == tag:\n",
    "                correct += 1\n",
    "        else:\n",
    "            pred_tag = unknown_words_rules(word)\n",
    "            if pred_tag == tag:\n",
    "                correct += 1\n",
    "print('The accuracy of test sample using baseline method is', correct/test_word*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到效果有一定的提升，目前的模型是以上所有方法里面最好的！"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 总结\n",
    "在训练集上：\n",
    "\n",
    "|Method|Accuracy|\n",
    "|---|---|\n",
    "|Baseline tagger|95.71961173164198|\n",
    "\n",
    "在测试集上：\n",
    "\n",
    "|Unknown Words Method|Accuracy|\n",
    "|---|---|\n",
    "|naive 'UNK'|93.03802632426513|\n",
    "|most frequent tag|94.51871255877869|\n",
    "|suffix tagging + naive 'UNK'|93.6907650355356|\n",
    "|suffix tagging + most frequent tag|94.55822042814506|\n",
    "|suffix tagging + other tag 'X'|93.73628497197947|\n",
    "|**corrected suffix tagging**|94.92667425332274|"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Task 3. Build an HMM tagger.\n",
    "根据上面对unknown words的处理方法对比，可以看到最后一种效果是最好的，因为它的分类是最细的，考虑情况是最完善的。因此，在HMM的模型中，我也考虑使用这种unknown words的处理方法。为了能让模型处理这些unknown words，首先要对训练集只出现一次的单词进行特征模糊，这是为了构建稀疏数据集，然后要对测试集只出现一次的单词同样进行特征模糊，这是为了让模型能够识别它。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c58ab053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the train dataset\n",
    "remove_words = []\n",
    "for i in range(train_sent):\n",
    "    for j in range(len(train_corpus[i])):\n",
    "        word = train_corpus[i][j][0]\n",
    "        tag = train_corpus[i][j][1]\n",
    "        if word_freq_dist[word] != 1:\n",
    "            continue\n",
    "        train_corpus[i][j] = ('UNK-' + unknown_words_rules(word), tag)\n",
    "        remove_words.append(word)\n",
    "# Process the test dataset\n",
    "for i in range(test_sent):\n",
    "    for j in range(len(test_corpus[i])):\n",
    "        word = test_corpus[i][j][0]\n",
    "        tag = test_corpus[i][j][1]\n",
    "        if word not in train_vocab or word in remove_words:\n",
    "            test_corpus[i][j] = ('UNK-' + unknown_words_rules(word), tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "vocab = set([word[0] for sent in train_corpus for word in sent])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def get_trans_matrix(corpus):\n",
    "    trans = nltk.ConditionalFreqDist([(sent[word_index][1], sent[word_index + 1][1]) for sent in corpus for word_index in range(len(sent)-1)])\n",
    "    trans = nltk.ConditionalProbDist(trans, nltk.MLEProbDist)\n",
    "    return trans\n",
    "\n",
    "def get_emission_matrix(corpus):\n",
    "    emission = nltk.ConditionalFreqDist([(word[1], word[0]) for sent in corpus for word in sent])\n",
    "    emission = nltk.ConditionalProbDist(emission, nltk.MLEProbDist)\n",
    "    return emission\n",
    "\n",
    "def get_prior_matrix(corpus):\n",
    "    # prior = nltk.UniformProbDist([sent[0][1] for sent in corpus])\n",
    "    prior = nltk.MLEProbDist(nltk.FreqDist([sent[0][1] for sent in corpus]))\n",
    "    return prior"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "train_trans = get_trans_matrix(train_corpus)\n",
    "train_emission = get_emission_matrix(train_corpus)\n",
    "train_prior = get_prior_matrix(train_corpus)\n",
    "model = nltk.tag.HiddenMarkovModelTagger(symbols = vocab, states = set(tags), transitions = train_trans, outputs = train_emission, priors = train_prior)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model HMM on train corpus is 96.89204342866253\n"
     ]
    }
   ],
   "source": [
    "# Test the model separately on train corpus and test corpus\n",
    "# On train corpus\n",
    "correct = 0\n",
    "for sent in train_corpus:\n",
    "    seq = [word[0] for word in sent]\n",
    "    true_label = [word[1] for word in sent]\n",
    "    pred_label = model.tag(seq)\n",
    "    correct += sum([true_label[i] == pred_label[i][1] for i in range(len(true_label))])\n",
    "print('The accuracy of model HMM on train corpus is', correct/train_word*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of model HMM on test corpus is 96.31546174822321\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for sent in test_corpus:\n",
    "    seq = [word[0] for word in sent]\n",
    "    true_label = [word[1] for word in sent]\n",
    "    pred_label = model.tag(seq)\n",
    "    correct += sum([true_label[i] == pred_label[i][1] for i in range(len(true_label))])\n",
    "print('The accuracy of model HMM on test corpus is', correct/test_word*100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可以看到HMM在训练集和测试集上的表现均有一定提升。这是因为HMM考虑到了语义的前后联系，利用到了tag之间变换的更多信息，因此建模更加贴合实际，也能减轻一些words本身歧义带来的干扰。\n",
    "另外，可以看到这种标注方法在训练集和测试集上的表现差距非常小（比baseline方法小得多），说明HMM标注器模型的鲁棒性非常好。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}